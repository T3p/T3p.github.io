---
layout: post
title: ICML 2019
---

# OPTIMIST: Optimistic Policy Optimization via Multiple Importance Sampling

**Matteo Papini**, [Alberto Metelli][6], [Lorenzo Lupo][11], Marcello Restelli, 36th International Conference on Machine Learning, Long Beach, 2019

* [Paper][3] \[[bibtex][4]\]
* Talk [video][14] and [slides][12]
* [Poster][13]
* [Code][2]
* [Download][1] the full text
* [MAPLE][16] talk (longer) \[[pdf][15]\]

![image-title-here](../images/palms.jpg){:class="img-responsive"}

[1]:{{ site.url }}/download/optimist.pdf
[2]:https://github.com/WolfLo/optimist
[3]:http://proceedings.mlr.press/v97/papini19a.html
[4]:{{ site.url }}/download/pmlr-v97-papini19a.bib
[6]:https://albertometelli.github.io/about/
[8]:https://icml.cc/Conferences/2019/ScheduleMultitrack?event=4049
[9]:https://icml.cc/Conferences/2019/ScheduleMultitrack?event=5158
[11]:https://linkedin.com/in/lupo-lorenzo
[12]:https://icml.cc/media/Slides/icml/2019/104(11-14-00)-11-14-25-5158-optimistic_poli.pdf
[13]:{{ site.url }}/download/poster_optimist.pdf
[14]:https://slideslive.com/38916704/reinforcement-learning-theory
[15]:{{ site.url }}/download/maple19.pdf
[16]:http://maple.polimi.it/
